#!/bin/sh

set -e 
set -x

# This script calculates diversity metrics on a pre-generated response file.
# IMPORTANT: It MUST be run AFTER reward_eval.sh has completed successfully.

# --- Step 0: Configuration ---
#export TRANSFORMERS_OFFLINE=1 # This is fine now, as no downloads are needed.
export CUDA_VISIBLE_DEVICES="1" # Use a single FREE GPU (e.g., 1, 2, or 3)

# --- Define Paths ---
# This is the base directory of the model whose responses we are evaluating
# MODEL_RESULTS_DIR="/data/ananthu/gem_project/results/qwen_1.5b_gem_run/output_dir"
MODEL_RESULTS_DIR="/data/ananthu/gem_project/results/qwen_1.5b_ce_run/output_dir"
# The tokenizer is needed to analyze the responses
TOKENIZER_PATH="/data/ananthu/gem_project/models/Qwen2-1.5B-Instruct"

# --- IMPORTANT ---
# This path points directly to the response file generated by reward_eval.sh
RESPONSE_FILE_PATH="${MODEL_RESULTS_DIR}/evaluation_chat_alpaca/generated_responses.json"

# Define a clean save directory for this specific evaluation's log
SAVE_DIR="${MODEL_RESULTS_DIR}/evaluation_diversity_alpaca"
mkdir -p $SAVE_DIR

# --- Step 1: Evaluate Diversity on the Existing Responses ---
echo "Calculating diversity metrics on responses from ${RESPONSE_FILE_PATH}"

# Note the corrected path to the python script
python evaluation/evaluation_diversity.py \
    --tokenizer_path $TOKENIZER_PATH \
    --detokenizer_path $TOKENIZER_PATH \
    --response_path "${RESPONSE_FILE_PATH}" \
    2>&1 | tee ${SAVE_DIR}/diversity_metrics.log

echo "Diversity evaluation complete. Results saved in ${SAVE_DIR}"